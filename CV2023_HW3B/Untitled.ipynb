{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d977aff6-bc1e-4c71-8be2-ffdf3fec1828",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,   200] loss: 2.073\n",
      "[1,   400] loss: 1.885\n",
      "[1,   600] loss: 1.812\n",
      "[1,   800] loss: 1.768\n",
      "[1,  1000] loss: 1.722\n",
      "[2,   200] loss: 1.695\n",
      "[2,   400] loss: 1.662\n",
      "[2,   600] loss: 1.643\n",
      "[2,   800] loss: 1.640\n",
      "[2,  1000] loss: 1.606\n",
      "[3,   200] loss: 1.599\n",
      "[3,   400] loss: 1.583\n",
      "[3,   600] loss: 1.576\n",
      "[3,   800] loss: 1.594\n",
      "[3,  1000] loss: 1.564\n",
      "[4,   200] loss: 1.565\n",
      "[4,   400] loss: 1.552\n",
      "[4,   600] loss: 1.540\n",
      "[4,   800] loss: 1.555\n",
      "[4,  1000] loss: 1.514\n",
      "[5,   200] loss: 1.524\n",
      "[5,   400] loss: 1.534\n",
      "[5,   600] loss: 1.516\n",
      "[5,   800] loss: 1.505\n",
      "[5,  1000] loss: 1.506\n",
      "[6,   200] loss: 1.505\n",
      "[6,   400] loss: 1.497\n",
      "[6,   600] loss: 1.503\n",
      "[6,   800] loss: 1.480\n",
      "[6,  1000] loss: 1.462\n",
      "[7,   200] loss: 1.472\n",
      "[7,   400] loss: 1.482\n",
      "[7,   600] loss: 1.489\n",
      "[7,   800] loss: 1.463\n",
      "[7,  1000] loss: 1.461\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n",
      "[8,   200] loss: 1.431\n",
      "[8,   400] loss: 1.416\n",
      "[8,   600] loss: 1.442\n",
      "[8,   800] loss: 1.427\n",
      "[8,  1000] loss: 1.416\n",
      "[9,   200] loss: 1.417\n",
      "[9,   400] loss: 1.403\n",
      "[9,   600] loss: 1.420\n",
      "[9,   800] loss: 1.419\n",
      "[9,  1000] loss: 1.415\n",
      "[10,   200] loss: 1.420\n",
      "[10,   400] loss: 1.407\n",
      "[10,   600] loss: 1.410\n",
      "[10,   800] loss: 1.407\n",
      "[10,  1000] loss: 1.400\n",
      "[11,   200] loss: 1.410\n",
      "[11,   400] loss: 1.390\n",
      "[11,   600] loss: 1.408\n",
      "[11,   800] loss: 1.401\n",
      "[11,  1000] loss: 1.395\n",
      "[12,   200] loss: 1.401\n",
      "[12,   400] loss: 1.378\n",
      "[12,   600] loss: 1.401\n",
      "[12,   800] loss: 1.404\n",
      "[12,  1000] loss: 1.407\n",
      "[13,   200] loss: 1.394\n",
      "[13,   400] loss: 1.383\n",
      "[13,   600] loss: 1.397\n",
      "[13,   800] loss: 1.419\n",
      "[13,  1000] loss: 1.390\n",
      "[14,   200] loss: 1.385\n",
      "[14,   400] loss: 1.410\n",
      "[14,   600] loss: 1.393\n",
      "[14,   800] loss: 1.389\n",
      "[14,  1000] loss: 1.393\n",
      "[15,   200] loss: 1.387\n",
      "[15,   400] loss: 1.409\n",
      "[15,   600] loss: 1.379\n",
      "[15,   800] loss: 1.387\n",
      "[15,  1000] loss: 1.369\n",
      "[16,   200] loss: 1.394\n",
      "[16,   400] loss: 1.364\n",
      "[16,   600] loss: 1.395\n",
      "[16,   800] loss: 1.391\n",
      "[16,  1000] loss: 1.371\n",
      "[17,   200] loss: 1.388\n",
      "[17,   400] loss: 1.370\n",
      "[17,   600] loss: 1.379\n",
      "[17,   800] loss: 1.374\n",
      "[17,  1000] loss: 1.377\n",
      "[18,   200] loss: 1.385\n",
      "[18,   400] loss: 1.383\n",
      "[18,   600] loss: 1.374\n",
      "[18,   800] loss: 1.372\n",
      "[18,  1000] loss: 1.381\n",
      "Epoch 00018: reducing learning rate of group 0 to 1.0000e-05.\n",
      "[19,   200] loss: 1.351\n",
      "[19,   400] loss: 1.360\n"
     ]
    }
   ],
   "source": [
    "# pylint: disable=all\n",
    "if __name__ == '__main__':\n",
    "    import torch\n",
    "    import torchvision\n",
    "    from torchvision import transforms\n",
    "    import torch.nn.functional as F\n",
    "    from torch import optim, nn\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    batch_size = 50\n",
    "    epoch_num = 20\n",
    "    disp_interval = 200\n",
    "\n",
    "    folder_path = './CV2023_HW3B'\n",
    "    model_path = '/cifar_net_N4.pth'\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root=folder_path+'/CIFAR10_data', train=True, download=True, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root=folder_path+'/CIFAR10_data', train=False, download=True, transform=transform_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    def imshow(img):\n",
    "        img = img.cpu()\n",
    "        img = img / 2 + 0.5\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        plt.show(block=False)\n",
    "        plt.pause(2)\n",
    "        plt.close()\n",
    "\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "            self.bn1 = nn.BatchNorm2d(32)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "            self.bn2 = nn.BatchNorm2d(64)\n",
    "            self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "            self.bn3 = nn.BatchNorm2d(128)\n",
    "            self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "            self.bn4 = nn.BatchNorm2d(256)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "            self.fc1 = nn.Linear(256 * 2 * 2, 512)\n",
    "            self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.bn1(self.conv1(self.dropout(x)))))\n",
    "            x = self.pool(F.relu(self.bn2(self.conv2(self.dropout(x)))))\n",
    "            x = self.pool(F.relu(self.bn3(self.conv3(self.dropout(x)))))\n",
    "            x = self.pool(F.relu(self.bn4(self.conv4(self.dropout(x)))))\n",
    "            \n",
    "            x = x.view(-1, 256 * 2 * 2) # Update the size for reshaping\n",
    "            x = F.relu(self.fc1(self.dropout(x)))\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    if 1:\n",
    "        net = Net().to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True)\n",
    "\n",
    "        for epoch in range(epoch_num):\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % disp_interval == disp_interval - 1:\n",
    "                    print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / disp_interval:.3f}')\n",
    "                    running_loss = 0.0\n",
    "            scheduler.step(loss)\n",
    "\n",
    "        print('Finished Training')\n",
    "        torch.save(net.state_dict(), model_path)\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = next(dataiter)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    imshow(torchvision.utils.make_grid(images))\n",
    "    print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n",
    "\n",
    "    net = Net().to(device)\n",
    "    net.load_state_dict(torch.load(model_path))\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(batch_size)))\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "\n",
    "    correct_pred = {classname: 0 for classname in classes}\n",
    "    total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction:\n",
    "                    correct_pred[classes[label]] += 1\n",
    "                total_pred[classes[label]] += 1\n",
    "\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
    "\n",
    "    conf_matrix = np.zeros((10, 10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            for i in range(len(labels)):\n",
    "                conf_matrix[labels[i]][predicted[i]] += 1\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.5)\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(x=j, y=i, s=int(conf_matrix[i, j]), va='center', ha='center', size='xx-large')\n",
    "\n",
    "    ax.set_xticks(np.arange(len(classes)))\n",
    "    ax.set_yticks(np.arange(len(classes)))\n",
    "    ax.set_xticklabels(classes, rotation=90)\n",
    "    ax.set_yticklabels(classes)\n",
    "\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "    plt.show(block=False)   # show the image without blocking the code\n",
    "    plt.pause(2)            # pause the code execution for 1 second\n",
    "    plt.close()             # close the image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
